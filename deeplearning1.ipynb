{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjzRhkxYU8hHoURjdG+YpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data2450/deep-learning-into/blob/main/deeplearning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S_7UC5cqF_L"
      },
      "source": [
        "url='https://raw.githubusercontent.com/data2450/deep-learning-into/main/Churn_Modelling.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54IxhoT6qgXH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km78wf7UqY2J",
        "outputId": "ca28a3bd-01a8-43ae-a395-e62faee5d4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data=pd.read_csv(url)\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt3az-pxwohJ",
        "outputId": "88d4a104-466e-4665-bd18-8fb462c39bc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIj0km5Yv7Vs",
        "outputId": "cccf008b-af0b-4e54-f007-b1dec3bbfd2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data.shape,\"\\n\")\n",
        "data.nunique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 14) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          10000\n",
              "CustomerId         10000\n",
              "Surname             2932\n",
              "CreditScore          460\n",
              "Geography              3\n",
              "Gender                 2\n",
              "Age                   70\n",
              "Tenure                11\n",
              "Balance             6382\n",
              "NumOfProducts          4\n",
              "HasCrCard              2\n",
              "IsActiveMember         2\n",
              "EstimatedSalary     9999\n",
              "Exited                 2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cAmszOmuOYk"
      },
      "source": [
        "**0 stands for not exited, which is 80% of the data, and 1 stands for Exited. Similarly, 0 stands for Active Member and 1 stands for not Active Member. The same applies to Credit Card.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vx4LulWq9zo"
      },
      "source": [
        "X = data.iloc[:, 3:13]\n",
        "y = data.iloc[:, 13]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQFnUUE7rDmR",
        "outputId": "4ef7ae0f-72dc-4cfe-a3b6-174d9c618c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619    France  Female  ...          1               1        101348.88\n",
              "1          608     Spain  Female  ...          0               1        112542.58\n",
              "2          502    France  Female  ...          1               0        113931.57\n",
              "3          699    France  Female  ...          0               0         93826.63\n",
              "4          850     Spain  Female  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4qAioTQtqxg",
        "outputId": "51aaa9c8-51e2-4cc6-ad88-0c3ee43d762f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIUaW8f_wfPg",
        "outputId": "a632f059-af55-41ab-d42a-b292eaf9b89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.value_counts()\n",
        "print('No exited', round(y.value_counts()[0]/len(y) * 100,2), '% of the dataset')\n",
        "print('exited', round(y.value_counts()[1]/len(y) * 100,2), '% of the dataset')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No exited 79.63 % of the dataset\n",
            "exited 20.37 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK1smb6kz1gc",
        "outputId": "4aa7d19a-0b1d-416d-c661-ae3d2adb0e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clE_BdFHwnSt"
      },
      "source": [
        "not doing any eda\n",
        "\n",
        "**lets create dummy variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf9HcLvCx6Fg"
      },
      "source": [
        "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFgY0AymxzlZ"
      },
      "source": [
        "## Concatenate the Data Frames\n",
        "\n",
        "X=pd.concat([X,geography,gender],axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRJ0yUIS0Klq"
      },
      "source": [
        "## Drop Unnecessary columns\n",
        "X=X.drop(['Geography','Gender'],axis=1)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcnOnT_V0N8o"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkNiJ2QTie7",
        "outputId": "79055a49-6fe6-4b54-9ddf-88d1161d52cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " y_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-vCns_k0VdU"
      },
      "source": [
        "# feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMmUFM_S0Seq"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZG51JK3ZsH"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfiNzTWh3XTy"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5saKs5wx4UAZ"
      },
      "source": [
        "The core data structures of Keras are layers and models. The simplest type of model is the Sequential model, a linear stack of layers\n",
        "\n",
        "**Dense implements the operation**: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
        "\n",
        "Note: If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 1 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units).\n",
        "\n",
        "Besides, layer attributes cannot be modified after the layer has been called once (except the trainable attribute).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UistXzFy-p0k"
      },
      "source": [
        "**LeakyReLU,PReLU,ELU** these  are activation function \n",
        "\n",
        "**Why do we need Non-linear activation functions :-**\n",
        "A neural network without an activation function is essentially just a linear regression model. The activation function does the non-linear transformation to the input making it capable to learn and perform more complex tasks.\n",
        "\n",
        "We know, neural network has neurons that work in correspondence of weight, bias and their respective activation function. In a neural network, we would update the weights and biases of the neurons on the basis of the error at the output. This process is known as back-propagation. Activation functions make the back-propagation possible since the gradients are supplied along with the error to update the weights and biases.\n",
        "**Dropout is a technique where randomly selected neurons are ignored during training.**\n",
        "**Dropout is a regularization** method that approximates training a large number of neural networks with different architectures in parallel.\n",
        "\n",
        "During training, some number of layer outputs are randomly ignored or “dropped out.” This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different “view” of the configured layer.\n",
        "\n",
        "drop out technique is used to avoid overfitting , during one iteration the algorithm will not consider that  randomly n.o of neurons as for the calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX3IYVbJ_dxP"
      },
      "source": [
        "# Initialising the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4is0pMrBheN"
      },
      "source": [
        "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q02OTIMTDv6E"
      },
      "source": [
        "**Adding input layer (First Hidden Layer)**\n",
        "We use the add method to add different layers to our ANN. The first parameter is the number of nodes you want to add to this layer. There is no rule of thumb as to how many nodes you should add. However, a common strategy is to choose the number of nodes as the average of nodes in the input layer and the number of nodes in the output layer.\n",
        "Say for example you had five independent variables and one output. Then you would take the sum of that and divide by two, which is three. You can also decide to experiment with a technique called parameter tuning. The second parameter, kernel_initializer, is the function that will be used to initialize the weights.\n",
        "In this case, it will use a uniform distribution to make sure that the weights are small numbers close to zero. The next parameter is the activation function. We use the Rectifier function, shortened as ReLU. We mostly use this function for the hidden layer in ANN. The final parameter is input_dim, which is the number of nodes in the input layer. It represents the number of independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yc6PCKJ4p5n"
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units=  6, kernel_initializer = 'uniform' ,activation='relu',input_shape=(11,)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcJFh1KO0YF0"
      },
      "source": [
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units= 6, kernel_initializer  = 'he_uniform',activation='relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer  = 'glorot_uniform', activation = 'sigmoid'))\n",
        "#since thses is a regresin prb we are using using sigmoid in the output layer\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEmU4EaSEmiy"
      },
      "source": [
        "We change the first parameter because in our output node we expect one node. This is because we are only interested in knowing whether a claim was fraudulent or not. We change the activation function because we want to get the probabilities that a claim is fraudulent. We do this by using the Sigmoid activation function.\n",
        "In case you’re dealing with a classification problem that has more than two classes (i.e. classifying cats, dogs, and monkeys) we’d need to change two things. We’d change the first parameter to 3 and change the activation function to softmax. Softmax is a sigmoid function applied to an independent variable with more than two categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeAbbLu7z9S"
      },
      "source": [
        "**adamax optimizer**:It is a variant of Adam based on the infinity norm\n",
        "\n",
        "**Arguments**\n",
        "\n",
        "**learning_rate**: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule. The learning rate.\n",
        "\n",
        "**beta_1**: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "\n",
        "**beta_2**: A float value or a constant float tensor. The exponential decay rate for the exponentially weighted infinity norm.\n",
        "**epsilon**: A small constant for numerical stability.\n",
        "\n",
        "**name**: Optional name for the operations created when applying gradients. Defaults to \"Adamax\".\n",
        "\n",
        "**kwargs**: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value.\n",
        "\n",
        "m = beta1 * m + (1 - beta) * g\n",
        "\n",
        "v = max(beta2 * v, abs(g))\n",
        "\n",
        "current_lr = learning_rate / (1 - beta1 ** t)\n",
        "\n",
        "w = w - current_lr * m / (v + epsilon)\n",
        "\n",
        "Similarly to Adam, the epsilon is added for numerical stability (especially to get rid of division by zero when v_t == 0).\n",
        "\n",
        "In contrast to Adam, the sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of tf.gather or an embedding lookup in the forward pass) only updates variable slices and corresponding m_t, v_t terms when that part of the variable was used in the forward pass. This means that the sparse behavior is contrast to the dense behavior (similar to some momentum implementations which ignore momentum unless a variable slice was actually used)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO_rI3OcEyE_"
      },
      "source": [
        "# Compiling the ANN\n",
        "Compiling is basically applying a stochastic gradient descent to the whole neural network. The first parameter is the algorithm you want to use to get the optimal set of weights in the neural network. The algorithm used here is a stochastic gradient algorithm.\n",
        "There are many variants of this. A very efficient one to use is Adam. The second parameter is the loss function within the stochastic gradient algorithm. Since our categories are binary, we use the binary_crossentropy loss function. Otherwise we would have used categorical_crossentopy. The final argument is the criterion we’ll use to evaluate our model. In this case we use the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0FMSjVy2bYi"
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-IpmgSVE8dU"
      },
      "source": [
        "# Fitting our ANN to the training set\n",
        "\n",
        "X_train represents the independent variables we’re using to train our ANN, and y_train represents the column we’re predicting. Epochs represents the number of times we’re going to pass our full dataset through the ANN. Batch_size is the number of observations after which the weights will be updated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWKGR6kBDGDy",
        "outputId": "f651fdff-2553-4a87-8866-4d41e7bba8cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7962 - val_loss: 0.4520 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.7962 - val_loss: 0.4373 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4275 - accuracy: 0.7962 - val_loss: 0.4318 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.7962 - val_loss: 0.4284 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4193 - accuracy: 0.7962 - val_loss: 0.4259 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4167 - accuracy: 0.8231 - val_loss: 0.4240 - val_accuracy: 0.8213\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8291 - val_loss: 0.4219 - val_accuracy: 0.8247\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4123 - accuracy: 0.8294 - val_loss: 0.4202 - val_accuracy: 0.8254\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4107 - accuracy: 0.8317 - val_loss: 0.4186 - val_accuracy: 0.8270\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4091 - accuracy: 0.8347 - val_loss: 0.4174 - val_accuracy: 0.8273\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4080 - accuracy: 0.8330 - val_loss: 0.4165 - val_accuracy: 0.8262\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.8339 - val_loss: 0.4158 - val_accuracy: 0.8266\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8354 - val_loss: 0.4151 - val_accuracy: 0.8262\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8352 - val_loss: 0.4141 - val_accuracy: 0.8270\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8350 - val_loss: 0.4137 - val_accuracy: 0.8266\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4040 - accuracy: 0.8371 - val_loss: 0.4134 - val_accuracy: 0.8270\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.8347 - val_loss: 0.4127 - val_accuracy: 0.8247\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4028 - accuracy: 0.8358 - val_loss: 0.4122 - val_accuracy: 0.8273\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8362 - val_loss: 0.4122 - val_accuracy: 0.8254\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8343 - val_loss: 0.4114 - val_accuracy: 0.8262\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8354 - val_loss: 0.4112 - val_accuracy: 0.8258\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4011 - accuracy: 0.8371 - val_loss: 0.4112 - val_accuracy: 0.8251\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4005 - accuracy: 0.8364 - val_loss: 0.4106 - val_accuracy: 0.8266\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4000 - accuracy: 0.8358 - val_loss: 0.4104 - val_accuracy: 0.8270\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8371 - val_loss: 0.4102 - val_accuracy: 0.8254\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.8358 - val_loss: 0.4093 - val_accuracy: 0.8289\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8373 - val_loss: 0.4095 - val_accuracy: 0.8270\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8352 - val_loss: 0.4086 - val_accuracy: 0.8285\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.8356 - val_loss: 0.4088 - val_accuracy: 0.8273\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8375 - val_loss: 0.4086 - val_accuracy: 0.8277\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8364 - val_loss: 0.4088 - val_accuracy: 0.8273\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8384 - val_loss: 0.4081 - val_accuracy: 0.8296\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8362 - val_loss: 0.4086 - val_accuracy: 0.8266\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3969 - accuracy: 0.8367 - val_loss: 0.4088 - val_accuracy: 0.8273\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3969 - accuracy: 0.8367 - val_loss: 0.4076 - val_accuracy: 0.8254\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3966 - accuracy: 0.8356 - val_loss: 0.4074 - val_accuracy: 0.8266\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3964 - accuracy: 0.8365 - val_loss: 0.4075 - val_accuracy: 0.8262\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.8371 - val_loss: 0.4071 - val_accuracy: 0.8285\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.8365 - val_loss: 0.4074 - val_accuracy: 0.8258\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8369 - val_loss: 0.4076 - val_accuracy: 0.8262\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8367 - val_loss: 0.4071 - val_accuracy: 0.8277\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8373 - val_loss: 0.4066 - val_accuracy: 0.8285\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8367 - val_loss: 0.4063 - val_accuracy: 0.8270\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8373 - val_loss: 0.4067 - val_accuracy: 0.8281\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3951 - accuracy: 0.8364 - val_loss: 0.4067 - val_accuracy: 0.8281\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8364 - val_loss: 0.4064 - val_accuracy: 0.8277\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3951 - accuracy: 0.8375 - val_loss: 0.4063 - val_accuracy: 0.8296\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8350 - val_loss: 0.4062 - val_accuracy: 0.8281\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8367 - val_loss: 0.4059 - val_accuracy: 0.8296\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8371 - val_loss: 0.4064 - val_accuracy: 0.8281\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8371 - val_loss: 0.4064 - val_accuracy: 0.8296\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8373 - val_loss: 0.4065 - val_accuracy: 0.8273\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8362 - val_loss: 0.4062 - val_accuracy: 0.8292\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8350 - val_loss: 0.4060 - val_accuracy: 0.8285\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8356 - val_loss: 0.4054 - val_accuracy: 0.8289\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8365 - val_loss: 0.4060 - val_accuracy: 0.8292\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8362 - val_loss: 0.4058 - val_accuracy: 0.8292\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8365 - val_loss: 0.4058 - val_accuracy: 0.8281\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3937 - accuracy: 0.8356 - val_loss: 0.4057 - val_accuracy: 0.8300\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8373 - val_loss: 0.4059 - val_accuracy: 0.8281\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8371 - val_loss: 0.4053 - val_accuracy: 0.8304\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3933 - accuracy: 0.8349 - val_loss: 0.4057 - val_accuracy: 0.8292\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8364 - val_loss: 0.4051 - val_accuracy: 0.8304\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8375 - val_loss: 0.4052 - val_accuracy: 0.8300\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8365 - val_loss: 0.4051 - val_accuracy: 0.8292\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8378 - val_loss: 0.4047 - val_accuracy: 0.8300\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8371 - val_loss: 0.4043 - val_accuracy: 0.8292\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8373 - val_loss: 0.4047 - val_accuracy: 0.8281\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8365 - val_loss: 0.4045 - val_accuracy: 0.8307\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8377 - val_loss: 0.4046 - val_accuracy: 0.8289\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8364 - val_loss: 0.4040 - val_accuracy: 0.8330\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3923 - accuracy: 0.8365 - val_loss: 0.4045 - val_accuracy: 0.8304\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8386 - val_loss: 0.4043 - val_accuracy: 0.8319\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8373 - val_loss: 0.4044 - val_accuracy: 0.8319\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8373 - val_loss: 0.4042 - val_accuracy: 0.8300\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3918 - accuracy: 0.8382 - val_loss: 0.4045 - val_accuracy: 0.8285\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8377 - val_loss: 0.4042 - val_accuracy: 0.8304\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3918 - accuracy: 0.8378 - val_loss: 0.4052 - val_accuracy: 0.8304\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8373 - val_loss: 0.4042 - val_accuracy: 0.8330\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3918 - accuracy: 0.8375 - val_loss: 0.4035 - val_accuracy: 0.8326\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3918 - accuracy: 0.8391 - val_loss: 0.4040 - val_accuracy: 0.8326\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8375 - val_loss: 0.4043 - val_accuracy: 0.8326\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8375 - val_loss: 0.4040 - val_accuracy: 0.8307\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8375 - val_loss: 0.4034 - val_accuracy: 0.8330\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8384 - val_loss: 0.4040 - val_accuracy: 0.8319\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8375 - val_loss: 0.4033 - val_accuracy: 0.8307\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8365 - val_loss: 0.4039 - val_accuracy: 0.8319\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8380 - val_loss: 0.4039 - val_accuracy: 0.8307\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8369 - val_loss: 0.4040 - val_accuracy: 0.8289\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3913 - accuracy: 0.8358 - val_loss: 0.4041 - val_accuracy: 0.8315\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8375 - val_loss: 0.4041 - val_accuracy: 0.8292\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8365 - val_loss: 0.4037 - val_accuracy: 0.8319\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8380 - val_loss: 0.4035 - val_accuracy: 0.8315\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8378 - val_loss: 0.4036 - val_accuracy: 0.8323\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.8384 - val_loss: 0.4036 - val_accuracy: 0.8304\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8378 - val_loss: 0.4033 - val_accuracy: 0.8319\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3907 - accuracy: 0.8371 - val_loss: 0.4029 - val_accuracy: 0.8323\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3907 - accuracy: 0.8362 - val_loss: 0.4031 - val_accuracy: 0.8319\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3907 - accuracy: 0.8378 - val_loss: 0.4034 - val_accuracy: 0.8319\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.8375 - val_loss: 0.4028 - val_accuracy: 0.8326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48_TFbdcFjw8",
        "outputId": "8f3c767f-c02a-47d1-8099-4ac40c58808e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxdp3UqxF46o",
        "outputId": "aff5db1e-0bc6-48e5-ebe5-4a28ab5b89c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKzh76RGIfK",
        "outputId": "b6180253-a192-45cc-a13e-749650aafab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZyddX33/9fnbLPvM9lmsgEBEhLWEEGr4gICStBiERW3uxV73+XW3kVaaNW63L1vrf2htVItKr1RK0hxiwXKjlBlSQgICQkkZJ1sM5lk9vXM+fz++F4zORlOkslyZpKZ9/PxmEfOtZ7vNQfOe77L9b3M3RERERkpNt4FEBGR45MCQkREclJAiIhITgoIERHJSQEhIiI5KSBERCQnBYTIMWBm/8/M/vco991kZu882vOI5JsCQkREclJAiIhITgoImTSipp0bzexFM+sysx+Y2VQzu9/MOszsYTOrytp/qZmtNrNWM3vczOZnbTvHzFZGx/0UKBzxXu8xsxeiY39nZmceYZk/aWbrzWyPmS0zsxnRejOzb5hZk5m1m9lLZrYw2na5mb0clW2bmX32iH5hMukpIGSyuQq4GDgVuAK4H/hroI7w/8OnAczsVOBO4M+jbfcBvzazlJmlgF8CPwKqgX+Pzkt07DnA7cCngBrgX4BlZlZwOAU1s7cD/xe4GpgObAbuijZfArwluo6KaJ+WaNsPgE+5exmwEHj0cN5XZIgCQiabf3L3Xe6+DXgSeMbdn3f3XuAXwDnRfh8A7nX3h9x9APgHoAh4I3ABkAS+6e4D7n4PsDzrPa4D/sXdn3H3QXe/A+iLjjscHwZud/eV7t4H3AxcaGZzgAGgDDgdMHdf4+47ouMGgAVmVu7ue9195WG+rwiggJDJZ1fW654cy6XR6xmEv9gBcPcMsBWoj7Zt8/1nutyc9Xo2cEPUvNRqZq3AzOi4wzGyDJ2EWkK9uz8KfBu4FWgys9vMrDza9SrgcmCzmf3GzC48zPcVARQQIgeynfBFD4Q2f8KX/DZgB1AfrRsyK+v1VuDv3L0y66fY3e88yjKUEJqstgG4+7fc/TxgAaGp6cZo/XJ3vxKYQmgKu/sw31cEUECIHMjdwLvN7B1mlgRuIDQT/Q54CkgDnzazpJn9IbAk69jvAX9qZm+IOpNLzOzdZlZ2mGW4E/iEmZ0d9V/8H0KT2CYzOz86fxLoAnqBTNRH8mEzq4iaxtqBzFH8HmQSU0CI5ODurwDXAv8E7CZ0aF/h7v3u3g/8IfBxYA+hv+LnWceuAD5JaALaC6yP9j3cMjwMfB74GaHWcjJwTbS5nBBEewnNUC3A16NtHwE2mVk78KeEvgyRw2Z6YJCIiOSiGoSIiOSkgBARkZwUECIikpMCQkREckqMdwGOldraWp8zZ854F0NE5ITy3HPP7Xb3ulzbJkxAzJkzhxUrVox3MURETihmtvlA29TEJCIiOSkgREQkJwWEiIjkNGH6IHIZGBigsbGR3t7e8S5K3hUWFtLQ0EAymRzvoojIBDGhA6KxsZGysjLmzJnD/hNvTizuTktLC42NjcydO3e8iyMiE8SEbmLq7e2lpqZmQocDgJlRU1MzKWpKIjJ28hoQZnapmb0SPVP3phzbP25mzdGze18wsz+J1p9tZk9FzwN+0cw+cBRlOJpLOGFMlusUkbGTtyYmM4sTnnZ1MdAILDezZe7+8ohdf+ru149Y1w181N3XRQ9pf87MHnD31mNdzsGM09zZR3lhguLUhG5xExE5LPmsQSwB1rv7hmj+/LuAK0dzoLu/6u7rotfbgSbCg+OPOXenqb2X7v7BfJye1tZW/vmf//mwj7v88stpbT3meSgiMmr5DIh6wqMXhzRG60a6KmpGusfMZo7caGZLgBTwWo5t15nZCjNb0dzcfESFHGqZyddjMQ4UEOl0+qDH3XfffVRWVuanUCIiozDendS/Bua4+5nAQ8Ad2RvNbDrwI+AT0UPj9+Put7n7YndfXFd3ZBUMIySEk5+EuOmmm3jttdc4++yzOf/883nzm9/M0qVLWbBgAQDvfe97Oe+88zjjjDO47bbbho+bM2cOu3fvZtOmTcyfP59PfvKTnHHGGVxyySX09PTkpawiItny2ei+jfCQ9yEN0bph7t6Stfh94O+HFsysHLgX+Bt3f/poC/OlX6/m5e3tObd19aVJJWIk44eXlwtmlPO3V5xx0H2++tWvsmrVKl544QUef/xx3v3ud7Nq1arh4ai333471dXV9PT0cP7553PVVVdRU1Oz3znWrVvHnXfeyfe+9z2uvvpqfvazn3HttdceVllFRA5XPmsQy4F5ZjbXzFKEZ+kuy94hqiEMWQqsidangF8AP3T3e/JYxmFj9eDVJUuW7Hevwre+9S3OOussLrjgArZu3cq6deted8zcuXM5++yzATjvvPPYtGnTGJVWRCazvNUg3D1tZtcDDwBx4HZ3X21mXwZWuPsy4NNmthRIEx7+/vHo8KuBtwA1Zja07uPu/sKRludgf+mv2tZGTWmK6RVFR3r6USspKRl+/fjjj/Pwww/z1FNPUVxczEUXXZTzXoaCgoLh1/F4XE1MIjIm8jqu093vA+4bse4LWa9vBm7OcdyPgR/ns2zZzPLXSV1WVkZHR0fObW1tbVRVVVFcXMzatWt5+umjbkkTETlmNPCf0FGdyVNC1NTU8KY3vYmFCxdSVFTE1KlTh7ddeumlfPe732X+/PmcdtppXHDBBXkpg4jIkTDP15/OY2zx4sU+8oFBa9asYf78+Yc8ds2OdkoLEsysLs5X8cbEaK9XRGSImT3n7otzbRvvYa7HBbOx66QWETlRKCAITUwTpSYlInKsKCDIbye1iMiJSgEBxNTEJCLyOgoI1MQkIpKLAgI1MYmI5KKAIDxsJ1/5cKTTfQN885vfpLu7+xiXSERkdBQQgEHebpRTQIjIiUp3UpPfJqbs6b4vvvhipkyZwt13301fXx/ve9/7+NKXvkRXVxdXX301jY2NDA4O8vnPf55du3axfft23va2t1FbW8tjjz2WnwKKiBzA5AmI+2+CnS/l3DQ1PUgm43C4jxydtggu++pBd8me7vvBBx/knnvu4dlnn8XdWbp0KU888QTNzc3MmDGDe++9FwhzNFVUVHDLLbfw2GOPUVtbe3jlEhE5BtTEFBmLPuoHH3yQBx98kHPOOYdzzz2XtWvXsm7dOhYtWsRDDz3EX/3VX/Hkk09SUVExBqURETm4yVODOMhf+rv3dtPek2bBjPK8FsHdufnmm/nUpz71um0rV67kvvvu43Of+xzveMc7+MIXvpDjDCIiY0c1CCBmlrdHjmZP9/2ud72L22+/nc7OTgC2bdtGU1MT27dvp7i4mGuvvZYbb7yRlStXvu5YEZGxNnlqEAdh5K+TOnu678suu4wPfehDXHjhhQCUlpby4x//mPXr13PjjTcSi8VIJpN85zvfAeC6667j0ksvZcaMGeqkFpExp+m+gZ1tPTR39LOo4cRu+9d03yJyuDTd9yFY1MQ0UcJSRORYUEAQmphAE/aJiGSb8AExmlqBmY163+PViVx2ETk+TeiAKCwspKWl5ZBfnlE+nLAT9rk7LS0tFBYWjndRRGQCmdCjmBoaGmhsbKS5ufmg+3X1pdnbPUCsrZB4zA667/GqsLCQhoaG8S6GiEwgeQ0IM7sU+EcgDnzf3b86YvvHga8D26JV33b370fbPgZ8Llr/v939jsN9/2Qyydy5cw+537+v2MqNy17kyb98GzOriw/3bUREJqS8BYSZxYFbgYuBRmC5mS1z95dH7PpTd79+xLHVwN8Ciwl9x89Fx+7NR1lTidDS1j+YycfpRUROSPnsg1gCrHf3De7eD9wFXDnKY98FPOTue6JQeAi4NE/lJBkPv4YBBYSIyLB8BkQ9sDVruTFaN9JVZvaimd1jZjMP51gzu87MVpjZikP1MxzMcECkT9BeahGRPBjvUUy/Bua4+5mEWsJh9TO4+23uvtjdF9fV1R1xIdTEJCLyevkMiG3AzKzlBvZ1RgPg7i3u3hctfh84b7THHkvJeBi5pCYmEZF98hkQy4F5ZjbXzFLANcCy7B3MbHrW4lJgTfT6AeASM6sysyrgkmhdXqSiJqb+tAJCRGRI3kYxuXvazK4nfLHHgdvdfbWZfRlY4e7LgE+b2VIgDewBPh4du8fMvkIIGYAvu/uefJVVndQiIq+X1/sg3P0+4L4R676Q9fpm4OYDHHs7cHs+yzdkqA9CASEiss94d1IfF4ZqEP2DGsUkIjJEAYH6IEREclFAAMmERjGJiIykgECd1CIiuSggyLpRTk1MIiLDFBDs64MYUCe1iMgwBQRZo5hUgxARGaaAAOIxI2bqgxARyaaAiKQSMQWEiEgWBUQkGY9pNlcRkSwKiEgqHlMfhIhIFgVEJBlXE5OISDYFRCSZMA1zFRHJooCIpNQHISKyHwVEJBmPMaA+CBGRYQqISCqhGoSISDYFRESd1CIi+1NARJJxYyCtTmoRkSEKiEgqEVcTk4hIFgVEJBU33SgnIpJFARFRH4SIyP7yGhBmdqmZvWJm683spoPsd5WZuZktjpaTZnaHmb1kZmvM7OZ8lhMUECIiI+UtIMwsDtwKXAYsAD5oZgty7FcGfAZ4Jmv1HwEF7r4IOA/4lJnNyVdZYWg2V3VSi4gMyWcNYgmw3t03uHs/cBdwZY79vgJ8DejNWudAiZklgCKgH2jPY1k1m6uIyAj5DIh6YGvWcmO0bpiZnQvMdPd7Rxx7D9AF7AC2AP/g7ntGvoGZXWdmK8xsRXNz81EVVp3UIiL7G7dOajOLAbcAN+TYvAQYBGYAc4EbzOykkTu5+23uvtjdF9fV1R1VedQHISKyv0Qez70NmJm13BCtG1IGLAQeNzOAacAyM1sKfAj4T3cfAJrM7LfAYmBDvgqb1BPlRET2k88axHJgnpnNNbMUcA2wbGiju7e5e627z3H3OcDTwFJ3X0FoVno7gJmVABcAa/NYVlLx0Entro5qERHIY0C4exq4HngAWAPc7e6rzezLUS3hYG4FSs1sNSFo/tXdX8xXWSGMYgLUUS0iEslnExPufh9w34h1XzjAvhdlve4kDHUdM8m4ATAw6BTk9bciInJi0J3UkWQ8/Cr0TAgRkUABERlqYlJHtYhIoICIDNUg1AchIhIoICKpoYBQE5OICKCAGDbcB6H5mEREAAXEsH2jmFSDEBEBBcQw3QchIrI/BUREfRAiIvtTQESSGuYqIrIfBURkXye1AkJEBBQQw4Y6qfvTGsUkIgIKiGEFamISEdmPAiKSVCe1iMh+FBAR9UGIiOxPARFRQIiI7E8BEdl3o5w6qUVEQAExLKUahIjIfhQQkX3DXBUQIiKggBgWjxlmqkGIiAxRQETMjGQ8psn6REQiCogsBfEYA7qTWkQEyHNAmNmlZvaKma03s5sOst9VZuZmtjhr3Zlm9pSZrTazl8ysMJ9lhTBhX//gYL7fRkTkhJDI14nNLA7cClwMNALLzWyZu788Yr8y4DPAM1nrEsCPgY+4++/NrAYYyFdZhyTjphqEiEgknzWIJcB6d9/g7v3AXcCVOfb7CvA1oDdr3SXAi+7+ewB3b3H3vP9pn4zH1EktIhLJZ0DUA1uzlhujdcPM7FxgprvfO+LYUwE3swfMbKWZ/WUeyzkslVAntYjIkFEFhJl9xszKLfhB9KV9ydG8sZnFgFuAG3JsTgB/AHw4+vd9ZvaOHOe4zsxWmNmK5ubmoykOEG6WUw1CRCQYbQ3iv7l7O6Hppwr4CPDVQxyzDZiZtdwQrRtSBiwEHjezTcAFwLKoo7oReMLdd7t7N3AfcO7IN3D329x9sbsvrqurG+WlHFgyHtONciIikdEGhEX/Xg78yN1XZ607kOXAPDOba2Yp4Bpg2dBGd29z91p3n+Puc4CngaXuvgJ4AFhkZsVRh/VbgZdf/xbHVjJuDGguJhERYPQB8ZyZPUgIiAeikUcH/VPb3dPA9YQv+zXA3e6+2sy+bGZLD3HsXkLz03LgBWBljn6KY043yomI7DPaYa5/DJwNbHD3bjOrBj5xqIPc/T5C81D2ui8cYN+LRiz/mDDUdcykEjE6+9Jj+ZYiIset0dYgLgRecfdWM7sW+BzQlr9ijY+U+iBERIaNNiC+A3Sb2VmEUUevAT/MW6nGie6DEBHZZ7QBkXZ3J9zo9m13v5UwCmlCSSZi6qQWEYmMtg+iw8xuJgxvfXN0D0Myf8UaH8m4qYlJRCQy2hrEB4A+wv0QOwn3NHw9b6UaJwUJNTGJiAwZVUBEofBvQIWZvQfodfeJ0wfR1wn9XRrmKiKSZbRTbVwNPAv8EXA18IyZvT+fBRszbdvg/9bDi3eHTmo1MYmIAKPvg/gb4Hx3bwIwszrgYeCefBVszJRNg3gK9m4kGb9QndQiIpHR9kHEhsIh0nIYxx7fYnGonA17Ng7P5hoGbImITG6jrUH8p5k9ANwZLX+AEXdIn9Cq58LejaTqwvRSA4NOKnGoqaZERCa2UQWEu99oZlcBb4pW3ebuv8hfscZY9Umw+XckY0MBkSGVmBgVJBGRIzXqR466+8+An+WxLOOnai70d1KWCbOHaKiriMghAsLMOoBcDfIGuLuX56VUY616LgBVfduAuIa6iohwiIBw9wk3nUZOVVFA9DYCszWSSUSEiTIS6WhVzQaMit5GAE23ISKCAiJIFEB5PWXdWwD1QYiIgAJin+q5lHSrBiEiMkQBMaR6LiWdqkGIiAxRQAypmkuqr4USelSDEBFBAbFPNNR1ljVpFJOICAqIfaKhrrNtl5qYRERQQOxTvS8gdKOciEieA8LMLjWzV8xsvZnddJD9rjIzN7PFI9bPMrNOM/tsPssJQGEF6cJq1SBERCJ5CwgziwO3ApcBC4APmtmCHPuVAZ8BnslxmluA+/NVxpEGK+Ywy3apk1pEhPzWIJYA6919g7v3A3cBV+bY7yvA14De7JVm9l5gI7A6j2Xcz2DlHGZbk2oQIiLkNyDqga1Zy43RumFmdi4w093vHbG+FPgr4EsHewMzu87MVpjZiubm5qMusFfNYYbtJj3Qf9TnEhE50Y1bJ7WZxQhNSDfk2PxF4Bvu3nmwc7j7be6+2N0X19XVHX2hqucSN6ego/HozyUicoIb9fMgjsA2YGbWckO0bkgZsBB43MwApgHLzGwp8Abg/Wb290AlkDGzXnf/dh7LS7zmJACKurbk821ERE4I+QyI5cA8M5tLCIZrgA8NbXT3NqB2aNnMHgc+6+4rgDdnrf8i0JnvcACI154MQEnn5ny/lYjIcS9vTUzungauBx4A1gB3u/tqM/tyVEs47iTLp7GLauqafjveRRERGXf5rEHg7vcB941Y94UD7HvRAdZ/8ZgX7EDMWFlxMRe33QNdu6Gk9tDHiIhMULqTeoSWk95HgkH6Xrh7vIsiIjKuFBAj1J9+HqszsxlYeed4F0VEZFwpIEZYVF/Bzwf/gNKWF2H3uvEujojIuFFAjFBbWsDy0reTIQa/v2u8iyMiMm4UEDnMaJjL8vhZ8OLdkNG0GyIyOSkgcjhzZgU/6bkQ2rbAlqfGuzgiIuNCAZHDmfWVPJhZTDpRAk//83gXR0RkXCggclhUX0EPhaxo+Bis/Q9Y/8h4F0lEZMwpIHKoKE4yp6aYH8eWQvVJcP9fQrpvvIslIjKmFBAHsKihkue398BlX4eW9fDUreNdJBGRMaWAOIAz6yvY1trD7ulvhtPfA098HVq3HvpAEZEJQgFxAIsaKgB4qbEN3vV/wDOw7H/CYHqcSyYiMjYUEAewsL4CM3h+aytUzYbL/h42PAYP5ZxrUERkwlFAHEBpQYLzZlXxHy9ux93hvI/BG/4Unr4VVv5wvIsnIpJ3CoiDuGbJLDY0d/Hsxj1hxSV/Bye9Df7jL2CTnhkhIhObAuIg3r1oOmWFCe58NnoEaTwBf/SvUDUHfvIB2Ky7rEVk4lJAHERRKs57z67nvlU7ae3uj1ZWwUd/BWXT4Efvg9ceHd9CiojkiQLiED64ZBb96Qy/eH7bvpUV9fCJ+6Hm5FCTWHvfgU8gInKCUkAcwoIZ5ZzVUMFdz24NndVDSuvgY7+GaYvg7o/CuofHr5AiInmggBiFDy6ZxSu7Oli5pXX/DcXVcO3PYcp8+OmHYdN/jU8BRUTyQAExClecNYOSVJzvP7nh9RuLKuEjv4DK2aG5qXHF2BdQRCQP8hoQZnapmb1iZuvN7KaD7HeVmbmZLY6WLzaz58zspejft+eznIdSUpDgU289mftX7eThl3fl2KE2dFyX1MIPr4RX7h/7QoqIHGN5CwgziwO3ApcBC4APmtmCHPuVAZ8BnslavRu4wt0XAR8DfpSvco7Wn771ZE6fVsbnfrmK9t6B1+9QPj10XNfOgzs/CE/eAtl9FiIiJ5h81iCWAOvdfYO79wN3AVfm2O8rwNeA3qEV7v68u2+PFlcDRWZWkMeyHlIqEeNrV51JU0cvX71/be6dymeEkFj4h/DIl+BnfwL93WNbUBGRYySfAVEPZE9/2hitG2Zm5wIz3f3eg5znKmClu7/ugQxmdp2ZrTCzFc3NzceizAd11sxK/vgP5vKTZ7bw9IaW3Dsli+CqH8DbPw+rfga3vwtat+S9bCIix9q4dVKbWQy4BbjhIPucQahdfCrXdne/zd0Xu/viurq6/BR0hL+4+DRm1xRzw92/Z29Xf+6dzOAtn4UP3gV7N8FtF8HGJ8ekfCIix0o+A2IbMDNruSFaN6QMWAg8bmabgAuAZVkd1Q3AL4CPuvtreSznYSlKxfnWNefQ3NHHZ376AoOZg/QznHYpfPJRKKqGO66AX10PnU1jV1gRkaOQz4BYDswzs7lmlgKuAZYNbXT3Nnevdfc57j4HeBpY6u4rzKwSuBe4yd2Pu1nxzppZyReXnsETrzbzj4+sO/jOtfNCSFz4Z/D7O+Fb58J/fQP6u8amsCIiRyhvAeHuaeB64AFgDXC3u682sy+b2dJDHH49cArwBTN7IfqZkq+yHokPLpnJ+89r4FuPrOPRtTmGvmYrLId3/R38j2dgzh/Aw1+EbyyE33wdeloPfqyIyDgxnyBDMRcvXuwrVoztTWq9A4P84T//ji17urnzkxcMP4XukLY+C0/8A6x7AFKlcOq7YP4VcMrFUFCa30KLiGQxs+fcfXHObQqIo7OzrZf3f/d3dPcPcvenLuSUKYfxBb/jRVj+fVh7L3TvhkQhnHY5nPkBOOUdEE/mr+AiIigg8m7j7i7+6Lu/IxWP8e///Y3UVxYd3gkyg7DlKVj9C1j1c+jZA8W1cP4fw5Lrwh3aIiJ5oIAYA6u3t3HNvzxNXXkB//6pC6kpPcL7+tL9sP7h8FjTV++HRBGc82E49VKYfhaUHlddMSJyglNAjJHlm/bwkR88w7wpZfzkk2+grPAom4iaX4HffQt+/1PIRNN7lE6DqWeEGWSnzIe5b4XKmQc/j4jIASggxtBja5v45A9XcN7sKu74b0soTMaP/qS97bDzJdjx+/DT9DLsfhXSvYCFkVFnXRNqGWqOEpHDoIAYY796YRt//tMXuOjUOm798LkUpxLH/k0yg9CyHl7+Vbi/Yk80FXnlbKg/FyoaIJYMHd11p8Hp74HEuE5nJSLHIQXEOPjJM1v43C9f4rRp5Xzvo+fRUFWcvzdzh20rYfNvYdtz4XVXc2iWyqTDPsW1cM61sGApVMyC4hqI6XEgIpOdAmKcPP5KE//zzudJxWN859rzWDK3euwLkcnAxsdh+Q/Ccyp8MKyPJaGwIixnBqGgDE66COZdHPo1isehrCIy5hQQ4+i15k4+eccKtuzp5m/ePZ+Pv3EOZjY+hWnfEWoYHTugfVu4izuehFgirHvtUehtC/sWVYXmqsqZoWO8dGpotjr93eHOcBGZEBQQ46ytZ4Ab7n6Bh9c0ccVZM/jqHy6ipCAP/RJHazAN21bAlqehdTPs3QxtW8MEg73RlCCpstBUtfgTgIWg6W6BuW/REFyRE5AC4jiQyTjf+c1r/H8PvsLc2hL+9oozeMupYzNF+TEx0Au7VsGzt4Wb+TIjnqoXT8Giq+GCPw2z13buCv0gqRIomx5+MgPQtTv8VM4MD1jKNjgQjuttCz+lU6Hm5LG7RpFJSAFxHPnt+t3c9PMX2bqnhzfPq+WvL5/P/OknWJNNx84wPUhBefiSTxTCC/8GL/wE0j2jP0/DElhwZQiXDY+FZ2b0d2TtYHDuR+Htn1PtRCRPFBDHmb70ID96ajP/9Oh6OnoH+OiFc/iLS06l/GhvrBtv3XvCdCEWC3/9l9RBf2fo3+jYEYKgpC7UMHa+GIbo7nwxHFs5O8w/Nf2s0P9RUB7uKH/mu+Fu8sUfh+qTQn9IQRn0dUBfe+hgn7YQpizYN3dVXwe0boWO7aHfpWcPTF0Isy4INRoRGaaAOE61dQ9wy0Ov8MOnN1NXWsDn37OAyxdNJx4bp07s8bB3UximWz039/bd6+Ghz4cRWBzkv9V4QThHZ1MIhFxiSZi5BGa/MYRFw5LcHe4du0LIJAtD7aiwEuLHYZ+RyDGggDjOvdjYyl//4iVWbWuntrSASxdO5fJF03nD3JrJFRYHMzgQ+jQ6doYv78LyUMtwh52/h+3PQ8sGKJsKlbPCT3k9lE0L+21fCRt+AxufCLUWz4SaTvVJofZRdxq0NYZJE/du2v+9Y4lwvuqToGRKCIt4KoRSqhiSxeG+kppToPbUUJPZ8hRs+i9oXhtCJlkUAqq3NXTq93dDRX04Z9XcMEKsfAZUzISSmnH5FcvkpIA4AaQHMzywehf3vrSdR9c20TuQYVp5IUvPnsF7z65n/vSy8RseO9H0dUBjNFpr1ypoWhPuRC+uhlkXhhpGSV2YymSgFzp3hu0tr0HP3hBWg/2Q7oOBbg5Ys4kXhODJDMJAVxglVlQFxVUhVNoaw3kHuvc/ru708IyQk94GezfCa4+FsPFMKGNRdQitwf5QlkQqrCuuDsvt28NPqiQ02827JNSudr8a5vdK98Ep74Rpi8Lz02VSU0CcYLr70zy6tolfPr+dx19pIp1x5k0p5YqzZnDFWRiEa6IAABM0SURBVDOYW6t29GMu3RdqBYf7hekOAz2hdtOyDnavC4+TnXUB1C8OzVSHOr6zCdobw5f6ng2w/pFwV/zQXfDl9eEmxmRxaD7r3hPCIp4KtZV0b1jXsycER3l9qI10NoXzDPbnfu/yBph5PvR1hueR9HeFmyeLqkONqPYUqD0tTApZfdL+vxv3UJsrKA19QmOlpxWWfy8MaDj7Q7Dw/Wr+O0oKiBPYnq5+7n1pB7/+/Xae3Rja1hdML+eyhdO4bNE0Tpkyhv9zytjpbYMtz0DVnPBc8yP9S7+vEzb+Jgwfrj011E48A68+AK/+Z6hBFVWFQEiVhIkhe/aGcOnYvu88RVHtavqZoRay5akw8ABCH03FzHDe3rYweKD2VDjtsvAArHRPaN7b9GRoWiufEX5SpVEtqD809xWWQ0FFGA7d8hrseS3U9qpPDufr74QVt4fzl9eHe3BqToG3/GWYQiY54jksg+kQvHs3hUELheVhMETV7HDNRyszGK53oCeEdLovhLpnwrxnNfNOiPBSQEwQO9p6uPfFHdy/aifPbd4LwClTSrls4TTedcY0zphRrmYoOXZ620ONaNeq8JjcLU+FL+3y+hAWM5eEL8e2raG5LJYINZBkcbhjf/vK/c835YzQDDbUBJbuiSaUTIUpX9K9+/YtrAjBUFgewqJtK2AhCN58A0xdBGv/Ax7/KjSthmTUnHby20ItbOuzoV/qQLWn6pPh5LeHn9620IS3+bfhfRdcGX4SBWEk3fqHw02jZqEM6b5QY+xu4aADJ5Il0HAezDg3DNMuqgqhONATQq6/M/zOEoXhd1Y5KzRJltQd+g+CzuYQiMfgEcUKiAloZ1svD6zeyX+u2skzG1vIOMyoKOStp9Xx1lOn8MZTak78YbNy/OnvCl9mo/lDpH0HrH8o7D/yTvuh753s86T7wxcnFoIke1t/V6h9lI64uTSTCTWkNb8OgdG5KwTOjHOg4fxQY6qaEwYB9LZB65YQIJt/G0JhqP+nqApmvynUirY9t/97lDeEZ7CEgkfDtWvDgIWiqvBFnSwOfUGxBFg8fPk3Loetz8DOVfvmQBuNwopQ7qEfi4Uw6t4dwnLX6vA6ngrzpp1+eaiplU0b/XtkUUBMcC2dfTyypolH1zbx2/W76ehLEzOYP72cN8yt4cKTw0/p8Ti9h8ixksmEL/+KhkP3/UCoCTQuD1/IU87YN7tx65ZwI2hmMHTm1512dJ35mQz0tYX+k76O0JRXUB7++h8cCDWn/s7QFNb8Kux+JTTjNa3JGrJtIYyq5sDUBaG87dtCKO7dBHXz4c+ePqLiKSAmkYHBDM9t3svTG1p4ZsMeVm7ZS186QyJmnDu7ijfMrebUqWWcNq2MOTUlpBKa8lvkuOQeNWMZFFVCLMfDx9xDkHTvDrW0IzBuAWFmlwL/CMSB77v7Vw+w31XAPcD57r4iWncz8MfAIPBpd3/gYO+lgMitLz3Iys2tPLGumSdebWbNjnYy0Ucejxkzq4qYW1vCadPKecu8Ws6bU0VB4hg8BU9ETgjjEhBmFgdeBS4GGoHlwAfd/eUR+5UB9wIp4Hp3X2FmC4A7gSXADOBh4FT3AzfkKSBGp3dgkNeaO1m3q5P1TZ1sbOliQ3MX65s6GBh0ilNx3nhyDW88uZY3nVLLqVNL1fEtMoEdLCDy2Si9BFjv7huiQtwFXAm8PGK/rwBfA27MWnclcJe79wEbzWx9dL6n8ljeSaEwGeeMGRWcMaNiv/VdfWmeeq2Fx19t4sl1u3l4TRMAlcVJGqqKmFZeyLSKQuZNCc1Tp08ro7I4NR6XICJjJJ8BUQ9szVpuBN6QvYOZnQvMdPd7zezGEcc+PeLY+pFvYGbXAdcBzJo16xgVe3IqKUjwzgVTeeeCqQA07u3md+tbeH7rXna09dK4t4dnNu6hozc9fExDVRFnNlSwsL6Ck2pLmFldzMzqYo2eEpkgxm1Yi5nFgFuAjx/pOdz9NuA2CE1Mx6ZkAtBQVczV5xdz9fkzh9e5O7va+1i7s521Ozt4aVsbLzW2cd9LO/c7dkZFIQtmVHDGjHIWzChn/rRyGqqKiGleKZETSj4DYhswM2u5IVo3pAxYCDwetXFPA5aZ2dJRHCvjwMyYVhGami46bd+Y9raeAbbu6Wbrnm42tXSzdmc7q7a18cjaXcPD3UtScWbXlFBfVUR9ZegYnze1lHlTyqgtTamfQ+Q4lM+AWA7MM7O5hC/3a4APDW109zagdmjZzB4HPht1UvcAPzGzWwid1POAZ/NYVjkKFUVJKupDU1O27v40r+7qZM2OdtbuaGfLnm42t3Txu/W76erfN96gvDDB7JoSZtcU01BVzJSyAqaWF1JVkqQoGacoFaesMMmUsgKScQ3LFRkreQsId0+b2fXAA4Rhrre7+2oz+zKwwt2XHeTY1WZ2N6FDOw382cFGMMnxqTiV4OyZlZw9s3K/9e5OU0cf63Z18uquDjbu7mLznm5ebGzjgdU7GRjM3VpoBlPKCphRWcSs6uIQKtXFzKkNr2tKVBMROZZ0o5wcVzIZp7VngKaOXvZ09dM3kKF3YJDWngF2tPWys62Hba09bG7pZntrz/A9HQAFiRjxmA03axUkYxQkYhQm41QWp6guTlJTWsCs6mLm1pZwUl3J6zrV3Z323jTFqbhqKzIpjNcwV5HDFosZ1SUpqksOPYS2P51h695utrR0s6mli+2tPbiHmoZ7uKu8dyBDz8Age7v7ae7sY82ODna29+53nrLCBPWVRfQODLKzvZfegQypeIxTp5VyxvQKZlYXUVqQoLQwSTzGcGjF4zFqS1LUlBZQVZykpCBBSSpBUSpOMm6qzcgJTwEhJ6xUIsbJdaWcXHd4M1r29A+ycXcXG3d30bi3m22tPWxv7aEwGeed86cytbyQ3Z19rN7ezoMv72Rv98CRlS8eoygVZ3pFIfWVRdSVFUSh4ZgZVcVJakoKqC0r4KTaEk6ZUkphUnexy/FDASGTTlEqzoJoCO5o9KUH6eobpLM3zaA7hckYBYk4A4MZWjr7aenqY2/3AN19aTr70vT0DzKQcQYGM3T1pdne2sv21h5e3NY2XMMZakobzGojixnUVxWFZwj1penuG6S8KMnU8gKmlBVQXJAgFY+RjBvTKoo4dWopp04tIxmPsbuzj5bOPhKxWBgpVlVEWUGCdMbpT2dIxE1TqMhhU0CIHEJBIk5BIp6z2Wtq+ShmDT2ATMZp6xlgV0cv65s6eXVXJ5t2d5GIG6UFoamqvWeAXe197GrvpWdPNwODGfrTGZo7+vbrf8llqKltSHVJiqnlhdSWpihOxSlMxikpSFBXGmoxlUVJ0pkMfQMZMg6zqos5qa6E6RWFh2wuc3c1qU1ACgiRcRKLGVUlKapKUpw+bXS1mSHZc2oNZpzasgJqS1OkB53GvT1s3dtNV1+aVDxGKhGjP51hZ3svO9t62d3VT3NHHz0Dg3T0ptnb3c/BxqoUJmNMKQvBUl1SQDIegsAdmjv72NHaw66OPmpLU5w2rZzTp5VRnAo1rIFBpySVYFpFGLrcl84M9xmlB334vpr6yiLmRPfJxHVD5XFDo5hEJrn0YIY9Xf209gyQiscoSMZwh00tXbzW3MWm3V3s7uyLmrH6ybgPB0ptaQHTKwuZWl7IrrZe1u7sYH1TJ/2DGeIxIxk3egcyr3vPyuLkcNNY9ldQMm7MrCqmobqYmVVFVBYnae0eYE9XPz0Dg1QXp6gtK6C6JEVJKk5RKkFBIkZnX5q2ngE6e9NkohPGzCgrTFBVnKKyOBnu1ylOUlmUoqwwQXEqnrPW4+7s7R6gLz1IYSJOQTJGYSI+YWcC0CgmETmgRDzGlPJCpoxoLptRWcQbT649wFEHNtSvMlQT6EsP0tTex872XlLxGLNriocnehwYzNDU0UfjnlCr2Li7my17uti6p4cXG1tp7xmgqjjUsoqScdbt6mR3Zx996deHDoR+nKGhzhn3gzbDxWOhKa84FacgEfqVuvrTNLX30T+4//nNoKwgQUVxuHlz3zlilBcmqChKUhkNo64pSVFakKCtJwRbR1+aklSc8sIkpYWJ4d+LATWloWY1payA7v5Bmjv6aOnqY0pZIadNKzvkaL6hZsqegUFmVBYddN8joRqEiBy3cvVtuDvd/YN09YcBAf3pDKWFCcoLk/vVCtydrv5B9nb109o9QFvPvp/23lDb6OgdoLt/kL50GLpcUpBgSnkBU8sKKUzG6UuHbV19aTp6Qy2lp39w+AFzA4MZ2nvC+r3d/ezp6iedlUqpeIyywgTd/YP0DBz+vb61pQWUFyXA9z392giB1dU3yO7OPtIZ59xZlfz8f7zpSH7FqkGIyIkpVxOQmYV7Tg7xCF2zUEMoLUgwszpfJdyfu9Pek6ajb4DK4tAMNnQN/ekMnX1phv4oH3Rnd0c/u9p7aeropaQgQW1paD7b2dbLKzs7eGVXx3AgZQefOxSn4tSVFVBXVsCcmpK8XI8CQkTkGDEzKopDX8dIqUSM6sT+TUZTygpzDrc+dWoZbzm1Lm/lHC3NJSAiIjkpIEREJCcFhIiI5KSAEBGRnBQQIiKSkwJCRERyUkCIiEhOCggREclpwky1YWbNwOajOEUtsPsYFedEMRmvGSbndU/Ga4bJed2He82z3T3nXXkTJiCOlpmtONB8JBPVZLxmmJzXPRmvGSbndR/La1YTk4iI5KSAEBGRnBQQ+9w23gUYB5PxmmFyXvdkvGaYnNd9zK5ZfRAiIpKTahAiIpKTAkJERHKa9AFhZpea2Stmtt7Mbhrv8uSLmc00s8fM7GUzW21mn4nWV5vZQ2a2Lvq3arzLeqyZWdzMnjez/4iW55rZM9Fn/lMzO/iDf09AZlZpZveY2VozW2NmF070z9rM/lf03/YqM7vTzAon4mdtZrebWZOZrcpal/OzteBb0fW/aGbnHs57TeqAMLM4cCtwGbAA+KCZLRjfUuVNGrjB3RcAFwB/Fl3rTcAj7j4PeCRanmg+A6zJWv4a8A13PwXYC/zxuJQqv/4R+E93Px04i3D9E/azNrN64NPAYndfCMSBa5iYn/X/Ay4dse5An+1lwLzo5zrgO4fzRpM6IIAlwHp33+Du/cBdwJXjXKa8cPcd7r4yet1B+MKoJ1zvHdFudwDvHZ8S5oeZNQDvBr4fLRvwduCeaJeJeM0VwFuAHwC4e7+7tzLBP2vCI5SLzCwBFAM7mICftbs/AewZsfpAn+2VwA89eBqoNLPpo32vyR4Q9cDWrOXGaN2EZmZzgHOAZ4Cp7r4j2rQTmDpOxcqXbwJ/CWSi5Rqg1d3T0fJE/MznAs3Av0ZNa983sxIm8Gft7tuAfwC2EIKhDXiOif9ZDznQZ3tU33GTPSAmHTMrBX4G/Lm7t2dv8zDmecKMezaz9wBN7v7ceJdljCWAc4HvuPs5QBcjmpMm4GddRfhreS4wAyjh9c0wk8Kx/Gwne0BsA2ZmLTdE6yYkM0sSwuHf3P3n0epdQ1XO6N+m8SpfHrwJWGpmmwjNh28ntM1XRs0QMDE/80ag0d2fiZbvIQTGRP6s3wlsdPdmdx8Afk74/Cf6Zz3kQJ/tUX3HTfaAWA7Mi0Y6pAidWsvGuUx5EbW9/wBY4+63ZG1aBnwsev0x4FdjXbZ8cfeb3b3B3ecQPttH3f3DwGPA+6PdJtQ1A7j7TmCrmZ0WrXoH8DIT+LMmNC1dYGbF0X/rQ9c8oT/rLAf6bJcBH41GM10AtGU1RR3SpL+T2swuJ7RTx4Hb3f3vxrlIeWFmfwA8CbzEvvb4vyb0Q9wNzCJMl361u4/sADvhmdlFwGfd/T1mdhKhRlENPA9c6+5941m+Y83MziZ0zKeADcAnCH8QTtjP2sy+BHyAMGLveeBPCO3tE+qzNrM7gYsI03rvAv4W+CU5PtsoLL9NaG7rBj7h7itG/V6TPSBERCS3yd7EJCIiB6CAEBGRnBQQIiKSkwJCRERyUkCIiEhOCgiR44CZXTQ026zI8UIBISIiOSkgRA6DmV1rZs+a2Qtm9i/RsyY6zewb0bMIHjGzumjfs83s6Wge/l9kzdF/ipk9bGa/N7OVZnZydPrSrGc4/Ft0k5PIuFFAiIySmc0n3Kn7Jnc/GxgEPkyYGG6Fu58B/IZwZyvAD4G/cvczCXewD63/N+BWdz8LeCNh9lEIM+z+OeHZJCcR5hISGTeJQ+8iIpF3AOcBy6M/7osIk6JlgJ9G+/wY+Hn0TIZKd/9NtP4O4N/NrAyod/dfALh7L0B0vmfdvTFafgGYA/xX/i9LJDcFhMjoGXCHu9+830qzz4/Y70jnr8meI2gQ/f8p40xNTCKj9wjwfjObAsPPAZ5N+P9oaMbQDwH/5e5twF4ze3O0/iPAb6Kn+TWa2XujcxSYWfGYXoXIKOkvFJFRcveXzexzwINmFgMGgD8jPJBnSbStidBPAWHa5e9GATA0oyqEsPgXM/tydI4/GsPLEBk1zeYqcpTMrNPdS8e7HCLHmpqYREQkJ9UgREQkJ9UgREQkJwWEiIjkpIAQEZGcFBAiIpKTAkJERHL6/wEqD0TkOMPPmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VngplffOdTi"
      },
      "source": [
        "# Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQV0rsSOOPs"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwXAKoq3GtNk"
      },
      "source": [
        "\n",
        "This will show us the probability of a claim being exited. We then set a threshold of 50% for classifying a claim as exited. This means that any claim with a probability of 0.5 or more will be classified as exited.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9izzcg-OoYV"
      },
      "source": [
        "y_pred = (y_pred > 0.5)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOf2yfGVS1hY",
        "outputId": "b7f10a97-ec93-40cf-8d79-d2652b919309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1595\n",
              "1     405\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2gHjI7hOrCq",
        "outputId": "61f7fd38-f6ce-4977-fd00-5250bf4b804f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1538,   57],\n",
              "       [ 257,  148]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTxMoUroTaHs",
        "outputId": "83a7aaed-1dcc-4160-cba0-1cdefe6ebf2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(1516 + 210) / 2000"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLShr887O6Db"
      },
      "source": [
        "The confusion matrix can be interpreted as follows. Out of 2000 observations, 1516 + 210 observations were correctly predicted while 79 + 195 were incorrectly predicted. You can calculate the accuracy by dividing the number of correct predictions by the total number of predictions. In this case (1516 + 210) / 2000, which gives you 86%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_xPKwaT178",
        "outputId": "6e5e0e44-9f28-49c7-b7e5-9317fe90d7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)\n",
        "score"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKUJom0UUCVr"
      },
      "source": [
        "Since our classifier expects numpy arrays, we have to transform the single observation into a numpy array and use the standard scaler to scale it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbFgzuziUcpO"
      },
      "source": [
        "# Evaluating our ANN\n",
        "After training the model one or two times, you’ll notice that you keep getting different accuracies. So you’re not quite sure which one is the right one. This introduces the bias variance trade off. In essence, we’re trying to train a model that will be accurate and not have too much variance of accuracy when trained several times.\n",
        "To solve this problem we use the K-fold cross validation with K equal to 10. This will split the training set into 10 folds. We’ll then train our model on 9 folds and test it on the remaining fold. Since we have 10 folds, we’re going to do this iteratively through 10 combinations. Each iteration will gives us its accuracy. We’ll then find the mean of all accuracies and use that as our model accuracy. We also calculate the variance to ensure that it’s minimal.\n",
        "Keras has a scikit learn wrapper (KerasClassifier) that enables us to include K-fold cross validation in our Keras code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSV9IsBaUDga"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzI5hNOCVBk6"
      },
      "source": [
        "Next we import the k-fold cross validation function from scikit_learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXQC9D2oVDvw"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0kBQNb_VHHq"
      },
      "source": [
        "The KerasClassifier expects one of its arguments to be a function, so we need to build that function.The purpose of this function is to build the architecture of our ANN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqntgVkcVKeL"
      },
      "source": [
        "def make_classifier():\n",
        "    classifier = Sequential()\n",
        "    classiifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu', input_dim=11))\n",
        "    classiifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(1, kernel_initializer = 'unifor', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "    return classifier"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnLyFKKZVoPl"
      },
      "source": [
        "This function will build the classifier and return it for use in the next step. The only thing we have done here is wrap our previous ANN architecture in a function and return the classifier.\n",
        "We then create a new classifier using K-fold cross validation and pass the parameter build_fn as the function we just created above. Next we pass the batch size and the number of epochs, just like we did in the previous classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu--2eH0VpEa"
      },
      "source": [
        "classifier = KerasClassifier(build_fn = make_classifier,\n",
        "                            batch_size=10, epochs=100)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfm7TkPGV1Yk"
      },
      "source": [
        "To apply the k-fold cross validation function we can use scikit-learn’s cross_val_score function. The estimator is the classifier we just built with make_classifier and n_jobs=-1 will make use of all available CPUs. cv is the number of folds and 10 is a typical choice. The cross_val_score will return the ten accuracies of the ten test folds used in the computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_h9DLFaQXS6"
      },
      "source": [
        "accuracies = cross_val_score(estimator =classifier ,\n",
        "                             X = X_train,\n",
        "                             y = y_train,\n",
        "                             cv = 10,\n",
        "                             n_jobs = -1)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLxjitF4SQ3w"
      },
      "source": [
        "To obtain the relative accuracies we get the mean of the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ifBnsOYEnq"
      },
      "source": [
        "mean = accuracies.mean()\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHrMPpKOVxwK"
      },
      "source": [
        "variance = accuracies.var()\n",
        "variance\n",
        "                             \n",
        "                             \n",
        "                              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLEbNawQ60u"
      },
      "source": [
        "# Fighting Overfitting\n",
        "\n",
        "Overfitting in machine learning is what happens when a model learns the details and noise in the training set such that it performs poorly on the test set. This can be observed when we have huge differences between the accuracies of the test set and training set, or when you observe a high variance when applying k-fold cross validation.\n",
        "In artificial neural networks, we counteract this using a technique called dropout regularization. Dropout regularization works by randomly disabling some neurons at each iteration of the training to prevent them from being too dependent on each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElP_DeHeRFVP"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "classifier1 = Sequential()\n",
        "classifier1.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu', input_dim=11))\n",
        "\n",
        "# Notice the dropouts\n",
        "classifier1.add(Dropout(rate = 0.1))\n",
        "classifier1.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier1.add(Dropout(rate = 0.1))\n",
        "\n",
        "classifier1.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "classifier1.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KnYsBPSmqN"
      },
      "source": [
        "In this case we apply the dropout after the first hidden layer and after the second hidden layer. Using a rate of 0.1 means that 1% of the neurons will be disabled at each iteration. It is advisable to start with a rate of 0.1. However you should never go beyond 0.4 because you will now start to get underfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F2Zi-1XUyfJ"
      },
      "source": [
        "# Parameter Tuning\n",
        "\n",
        "Once you obtain your accuracy you can tune the parameters to get a higher accuracy. Grid Search enables us to test different parameters in order to obtain the best parameters.\n",
        "The first step here is to import the GridSearchCV module from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARUxXFEySngd"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpYdJp3EWplu"
      },
      "source": [
        "We also need to modify our make_classifier function as follows. We create a new variable called optimizer that will allow us to add more than one optimizer in our params variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwXpe9JTWqUk"
      },
      "source": [
        "def make_classifier(optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu', input_dim=11))\n",
        "    classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer= optimizer,loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "    return classifier"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_yQ2x9XQjw"
      },
      "source": [
        "We’ll still use the KerasClassifier, but we won’t pass the batch size and number of epochs since these are the parameters we want to tune."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvLxeGW6XOFg"
      },
      "source": [
        "classifier = KerasClassifier(build_fn = make_classifier)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTMWvbLwXgZd"
      },
      "source": [
        "The next step is to create a dictionary with the parameters we’d like to tune — in this case the batch size, the number of epochs, and the optimizer function. We still use Adam as an optimizer and add a new one called rmsprop. The Keras documentation recommends rmsprop when dealing with Recurrent Neural Networks. However we can try it for this ANN to see if it gives us a better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuPPhItxXTNl"
      },
      "source": [
        "params = {\n",
        "    'batch_size':[20,35],\n",
        "    'nb_epoch':[150,500],\n",
        "    'optimizer':['adammax','adam']\n",
        "}"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7utXHzDXlfE"
      },
      "source": [
        "grid_search = GridSearchCV(estimator=classifier,\n",
        "                           param_grid=params,\n",
        "                           scoring='accuracy',\n",
        "                           cv=10)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icSF2e0dXtlP",
        "outputId": "3eabc89c-64c0-4814-a665-70328630a6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid_search = grid_search.fit(X_train,y_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unknown optimizer: adammax\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "360/360 [==============================] - 0s 949us/step - loss: 0.5299 - accuracy: 0.7969\n",
            "360/360 [==============================] - 0s 892us/step - loss: 0.5548 - accuracy: 0.7957\n",
            "360/360 [==============================] - 0s 888us/step - loss: 0.5281 - accuracy: 0.7956\n",
            "360/360 [==============================] - 0s 856us/step - loss: 0.5239 - accuracy: 0.7975\n",
            "360/360 [==============================] - 0s 864us/step - loss: 0.5613 - accuracy: 0.7904\n",
            "360/360 [==============================] - 0s 899us/step - loss: 0.5539 - accuracy: 0.7939\n",
            "360/360 [==============================] - 0s 909us/step - loss: 0.5232 - accuracy: 0.7969\n",
            "360/360 [==============================] - 0s 899us/step - loss: 0.5391 - accuracy: 0.7957\n",
            "360/360 [==============================] - 0s 887us/step - loss: 0.5408 - accuracy: 0.7953\n",
            "360/360 [==============================] - 0s 930us/step - loss: 0.6491 - accuracy: 0.7942\n",
            "360/360 [==============================] - 0s 898us/step - loss: 0.5562 - accuracy: 0.7956\n",
            "360/360 [==============================] - 0s 884us/step - loss: 0.5555 - accuracy: 0.7962\n",
            "360/360 [==============================] - 0s 899us/step - loss: 0.5310 - accuracy: 0.7954\n",
            "360/360 [==============================] - 0s 919us/step - loss: 0.5391 - accuracy: 0.7975\n",
            "360/360 [==============================] - 0s 896us/step - loss: 0.5386 - accuracy: 0.7928\n",
            "360/360 [==============================] - 0s 875us/step - loss: 0.5526 - accuracy: 0.7933\n",
            "360/360 [==============================] - 0s 892us/step - loss: 0.5373 - accuracy: 0.7965\n",
            "360/360 [==============================] - 0s 922us/step - loss: 0.5319 - accuracy: 0.7961\n",
            "360/360 [==============================] - 0s 871us/step - loss: 0.5362 - accuracy: 0.7943\n",
            "360/360 [==============================] - 0s 886us/step - loss: 0.5383 - accuracy: 0.7943\n",
            "206/206 [==============================] - 0s 991us/step - loss: 0.5940 - accuracy: 0.7962\n",
            "206/206 [==============================] - 0s 966us/step - loss: 0.5956 - accuracy: 0.7961\n",
            "206/206 [==============================] - 0s 934us/step - loss: 0.5911 - accuracy: 0.7954\n",
            "206/206 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7949\n",
            "206/206 [==============================] - 0s 970us/step - loss: 0.5950 - accuracy: 0.7919\n",
            "206/206 [==============================] - 0s 954us/step - loss: 0.6409 - accuracy: 0.7910\n",
            "206/206 [==============================] - 0s 955us/step - loss: 0.5949 - accuracy: 0.7957\n",
            "206/206 [==============================] - 0s 968us/step - loss: 0.5894 - accuracy: 0.7947\n",
            "206/206 [==============================] - 0s 917us/step - loss: 0.6087 - accuracy: 0.7942\n",
            "206/206 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7961\n",
            "206/206 [==============================] - 0s 940us/step - loss: 0.5910 - accuracy: 0.7972\n",
            "206/206 [==============================] - 0s 961us/step - loss: 0.6092 - accuracy: 0.7939\n",
            "206/206 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.7949\n",
            "206/206 [==============================] - 0s 933us/step - loss: 0.6129 - accuracy: 0.7975\n",
            "206/206 [==============================] - 0s 938us/step - loss: 0.5924 - accuracy: 0.7929\n",
            "206/206 [==============================] - 0s 962us/step - loss: 0.5799 - accuracy: 0.7944\n",
            "206/206 [==============================] - 0s 959us/step - loss: 0.5921 - accuracy: 0.7957\n",
            "206/206 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.7949\n",
            "206/206 [==============================] - 0s 945us/step - loss: 0.6177 - accuracy: 0.7940\n",
            "206/206 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.7961\n",
            "400/400 [==============================] - 0s 890us/step - loss: 0.5324 - accuracy: 0.7949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXVkYJm1ahVV"
      },
      "source": [
        "We can get the best selection of parameters using best_params from the grid search object. Likewise we use the best_score_ to get the best score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXnewq9Z6wy",
        "outputId": "347fd787-7864-44a1-bf4a-dc463049851f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_param = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print(best_param)\n",
        "\n",
        "best_accuracy"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 20, 'nb_epoch': 150, 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    }
  ]
}